{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_data/description.csv\", index_col = [0])\n",
    "bad_idxs = []\n",
    "for idxs, file in enumerate(df['image_name']):\n",
    "    path = f\"{'preprocessed_data/images'}/{file}\"\n",
    "    if( not os.path.isfile(path)):\n",
    "        bad_idxs.append(idxs)\n",
    "df = df.drop(bad_idxs)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwanDataset(Dataset):\n",
    "    def __init__(self, img_folder, description_df) -> None:\n",
    "        super().__init__()\n",
    "        self.size = (256, 256)\n",
    "        self.img_folder = img_folder\n",
    "        self.description_df = description_df\n",
    "        self.labels = self.description_df.swan_id.to_list()\n",
    "        self.imgs = self.description_df.image_name.to_list()\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(self.size),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.description_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(f\"{self.img_folder}/{self.imgs[idx]}\")\n",
    "        if(len(img.shape) > 3):\n",
    "            img = img[:,:,:3]\n",
    "        label = self.labels[idx]\n",
    "        x = self.transforms(img)\n",
    "        return (x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "train_ds = SwanDataset(\"preprocessed_data/images\", train_df)\n",
    "val_ds = SwanDataset(\"preprocessed_data/images\", val_df)\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(dataset=val_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4834\n",
       "0    3465\n",
       "2    2963\n",
       "Name: swan_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['swan_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1189\n",
       "0     892\n",
       "2     735\n",
       "Name: swan_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['swan_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lakomchik/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lakomchik/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.classifier[6] = nn.Linear(4096, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler = None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train(True)  # Set the model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_accuracy*100:.2f}%\")\n",
    "        if(scheduler is not None):\n",
    "            scheduler.step()\n",
    "        # Validation evaluation\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_correct_predictions = 0\n",
    "        val_total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in tqdm(val_loader):\n",
    "                val_images = val_images.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_images)\n",
    "                val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                val_predicted = val_outputs.argmax(dim=1)\n",
    "                val_total_samples += val_labels.size(0)\n",
    "                val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader)\n",
    "        val_epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Val Loss: {val_epoch_loss:.4f} | Val Accuracy: {val_epoch_accuracy*100:.2f}%\")\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vgg16.parameters(), lr = 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb2fe37231f4309866f3f8337fe2b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.9368 | Train Accuracy: 55.26%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32561467f2204f5183bf19b526f9d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Val Loss: 0.6635 | Val Accuracy: 72.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661a9f89a4a84b9e8c60bd712198dc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 0.6602 | Train Accuracy: 71.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e42b9a1199e452d922ed4139bfcf0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Val Loss: 0.6341 | Val Accuracy: 70.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421febf34cc04a41a412be19d727d859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.6033 | Train Accuracy: 75.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e3524907144d1f85ed4f87b9d7196f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Val Loss: 0.5826 | Val Accuracy: 77.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0deec3e92364596a6846218d9c68ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.5088 | Train Accuracy: 81.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5295663c27384447bbcd86562f556986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Val Loss: 0.5008 | Val Accuracy: 82.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa8d7dc5df484c86ec7b2b823a23a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(vgg16, train_dl, val_dl, criterion, optimizer, num_epoch, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg16.state_dict(), 'vgg_0.8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_perfomance(model, val_loader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_labels in tqdm(val_loader):\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_images)\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            predicted_labels += list(val_predicted.cpu().numpy())\n",
    "            real_labels += list(val_labels.cpu().numpy())\n",
    "    return predicted_labels, real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38ca0b2682b4c998383db0b7423a007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred, y_true = calculate_model_perfomance(vgg16, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916193181818182"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_true).sum()/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215, 634,   2],\n",
       "       [249, 997,   4],\n",
       "       [113, 148, 454]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true,y_pred)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
